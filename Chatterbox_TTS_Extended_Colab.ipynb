{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéß Chatterbox-TTS-Extended on Google Colab\n",
    "\n",
    "## Advanced Text-to-Speech with Artifact Reduction\n",
    "\n",
    "This notebook allows you to run Chatterbox-TTS-Extended on Google Colab, leveraging free GPU resources for high-quality speech synthesis with built-in artifact reduction.\n",
    "\n",
    "### Features:\n",
    "- üé§ High-quality voice cloning and TTS\n",
    "- üîß Advanced artifact reduction with RNNoise\n",
    "- üéØ Whisper-based quality validation\n",
    "- üé® Voice conversion capabilities\n",
    "- üì¶ Multiple export formats (WAV, MP3, FLAC)\n",
    "\n",
    "### Requirements:\n",
    "- Google Colab account (free tier works!)\n",
    "- GPU runtime (recommended: T4 or better)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-links"
   },
   "source": [
    "## üìö Quick Links & Resources\n",
    "\n",
    "**Documentation:**\n",
    "- üìñ [Full Colab Guide](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/COLAB_GUIDE.md) - Comprehensive guide\n",
    "- ‚ö° [Quick Reference](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/COLAB_QUICKREF.md) - Cheat sheet\n",
    "- üìã [README](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/README.md) - Feature documentation\n",
    "\n",
    "**Support:**\n",
    "- üêõ [Report Issues](https://github.com/m-marie1/Chatterbox-TTS-Extended/issues)\n",
    "- üí¨ [Discussions](https://github.com/m-marie1/Chatterbox-TTS-Extended/discussions)\n",
    "\n",
    "**Tips:**\n",
    "- ‚ö° For fastest start: Run all cells and accept default settings\n",
    "- üéØ For best quality: Enable RNNoise + use 3 candidates + Whisper validation\n",
    "- üíæ Remember to download files before session ends!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## üìã Step 1: Environment Setup\n",
    "\n",
    "**IMPORTANT**: Make sure you have enabled GPU runtime:\n",
    "1. Go to `Runtime` ‚Üí `Change runtime type`\n",
    "2. Select `GPU` as Hardware accelerator\n",
    "3. Choose `T4` GPU (or better if available)\n",
    "4. Click `Save`\n",
    "\n",
    "This cell will:\n",
    "- Check GPU availability\n",
    "- Verify Python version\n",
    "- Display system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-environment"
   },
   "outputs": [],
   "source": [
    "# Check GPU and environment\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"üîç Checking environment...\\n\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi'], encoding='utf-8')\n",
    "    print(\"\\n‚úÖ GPU detected:\")\n",
    "    print(gpu_info)\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: No GPU detected. This will be VERY slow!\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-system-deps"
   },
   "source": [
    "## üì¶ Step 2: Install System Dependencies\n",
    "\n",
    "Installing FFmpeg and other system-level tools required for audio processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-ffmpeg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install FFmpeg (required for audio processing)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg\n",
    "\n",
    "# Verify FFmpeg installation\n",
    "!ffmpeg -version | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## üì• Step 3: Clone Repository\n",
    "\n",
    "Cloning the Chatterbox-TTS-Extended repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "git-clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists('Chatterbox-TTS-Extended'):\n",
    "    print(\"üìÅ Removing existing directory...\")\n",
    "    !rm -rf Chatterbox-TTS-Extended\n",
    "\n",
    "# Clone the repository\n",
    "print(\"üì• Cloning Chatterbox-TTS-Extended repository...\")\n",
    "!git clone https://github.com/m-marie1/Chatterbox-TTS-Extended.git\n",
    "\n",
    "# Change to repository directory\n",
    "%cd Chatterbox-TTS-Extended\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-python-deps"
   },
   "source": [
    "## üêç Step 4: Install Python Dependencies\n",
    "\n",
    "Installing all required Python packages. This may take 3-5 minutes.\n",
    "\n",
    "**Note**: We're using Colab-optimized versions to avoid conflicts with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support (Colab uses CUDA 12.x)\n",
    "print(\"üîß Installing PyTorch with CUDA support...\")\n",
    "!pip install -q torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install core dependencies\n",
    "print(\"\\nüì¶ Installing core dependencies...\")\n",
    "!pip install -q gradio numpy faster-whisper openai-whisper ffmpeg-python\n",
    "!pip install -q resampy==0.4.3 librosa==0.10.0 soundfile nltk\n",
    "\n",
    "# Install auto-editor for audio cleanup\n",
    "print(\"\\nüé¨ Installing auto-editor...\")\n",
    "!pip install -q auto-editor==27.1.1\n",
    "\n",
    "# Install Hugging Face and model dependencies\n",
    "print(\"\\nü§ó Installing Hugging Face dependencies...\")\n",
    "!pip install -q transformers==4.46.3 diffusers==0.29.0 omegaconf==2.3.0\n",
    "\n",
    "# Install specific model dependencies\n",
    "print(\"\\nüéØ Installing model-specific dependencies...\")\n",
    "!pip install -q resemble-perth==1.0.1 silero-vad==5.1.2 conformer==0.3.2\n",
    "\n",
    "# Install pyrnnoise for artifact reduction\n",
    "print(\"\\nüîá Installing pyrnnoise for noise reduction...\")\n",
    "!pip install -q pyrnnoise==0.3.8\n",
    "\n",
    "# Install s3tokenizer\n",
    "print(\"\\nüî§ Installing s3tokenizer...\")\n",
    "!pip install -q s3tokenizer\n",
    "\n",
    "# Install spaces (for Gradio compatibility)\n",
    "print(\"\\nüöÄ Installing spaces...\")\n",
    "!pip install -q spaces\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed successfully!\")\n",
    "\n",
    "# Verify key installations\n",
    "print(\"\\nüìä Verifying installations...\")\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-nltk"
   },
   "source": [
    "## üìö Step 5: Download NLTK Data\n",
    "\n",
    "Downloading required NLTK tokenizer data for text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nltk-download"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "print(\"üìö Downloading NLTK data...\")\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "print(\"‚úÖ NLTK data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch-ui"
   },
   "source": [
    "## üöÄ Step 6: Launch Chatterbox-TTS-Extended\n",
    "\n",
    "This will start the Gradio interface. The model will be loaded on first use.\n",
    "\n",
    "**Features available:**\n",
    "- **TTS Tab**: Text-to-Speech with advanced options\n",
    "  - Multiple candidate generation for best quality\n",
    "  - Whisper validation to reduce artifacts\n",
    "  - RNNoise denoising for clean audio\n",
    "  - Auto-editor for silence removal\n",
    "  - Batch processing support\n",
    "- **Voice Conversion Tab**: Convert voice to match a reference\n",
    "\n",
    "**Tips for Colab:**\n",
    "- First generation will take longer as models load\n",
    "- Use smaller Whisper models (tiny/base) to save VRAM\n",
    "- Enable \"Use faster-whisper\" for better performance\n",
    "- Start with 1-2 candidates per chunk to avoid OOM errors\n",
    "- If you get CUDA out of memory, restart runtime and reduce settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch-app",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "print(\"üöÄ Launching Chatterbox-TTS-Extended...\\n\")\n",
    "print(\"‚è≥ First generation will take longer as models download and load.\")\n",
    "print(\"üìä Monitor the output below for progress updates.\\n\")\n",
    "\n",
    "# Run with public sharing enabled for Colab\n",
    "!python Chatter.py --share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommended-settings"
   },
   "source": [
    "## ‚öôÔ∏è Recommended Settings for Colab\n",
    "\n",
    "### For Free Tier (T4 GPU, ~15GB VRAM):\n",
    "```\n",
    "Whisper Model: tiny or base\n",
    "Use faster-whisper: ‚úÖ Enabled\n",
    "Candidates per chunk: 2-3\n",
    "Parallel workers: 2-3\n",
    "Enable RNNoise: ‚úÖ Enabled (removes artifacts!)\n",
    "```\n",
    "\n",
    "### For Pro/Pro+ (A100/V100, more VRAM):\n",
    "```\n",
    "Whisper Model: small or medium\n",
    "Use faster-whisper: ‚úÖ Enabled\n",
    "Candidates per chunk: 3-5\n",
    "Parallel workers: 4-6\n",
    "Enable RNNoise: ‚úÖ Enabled\n",
    "```\n",
    "\n",
    "### To Reduce Artifacts (Main Goal!):\n",
    "1. **Enable RNNoise denoising** - This is the key feature!\n",
    "2. Use **3+ candidates per chunk** with Whisper validation\n",
    "3. Enable **Auto-Editor** for cleanup\n",
    "4. Use **faster-whisper** for efficient validation\n",
    "5. Set **Max Attempts to 3** to retry failed chunks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "#### 1. **CUDA Out of Memory Error**\n",
    "```python\n",
    "# Solution: Restart runtime and reduce settings\n",
    "# Runtime ‚Üí Restart runtime\n",
    "# Then use these settings:\n",
    "# - Whisper model: tiny\n",
    "# - Candidates: 1-2\n",
    "# - Parallel workers: 1\n",
    "```\n",
    "\n",
    "#### 2. **Slow Performance**\n",
    "```python\n",
    "# Make sure GPU is enabled:\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "# If False, go to Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "```\n",
    "\n",
    "#### 3. **Model Download Failures**\n",
    "```python\n",
    "# Retry the cell or check your internet connection\n",
    "# Models are downloaded from Hugging Face on first use\n",
    "```\n",
    "\n",
    "#### 4. **Audio Has Noise/Artifacts**\n",
    "```python\n",
    "# Enable these features in the UI:\n",
    "# ‚úÖ Denoise with RNNoise (pyrnnoise)\n",
    "# ‚úÖ Post-process with Auto-Editor\n",
    "# ‚úÖ Use faster-whisper validation\n",
    "# Increase candidates per chunk to 3-5\n",
    "```\n",
    "\n",
    "#### 5. **Session Timeout**\n",
    "```python\n",
    "# Colab free tier has time limits\n",
    "# Save your audio files regularly\n",
    "# Consider upgrading to Colab Pro for longer sessions\n",
    "```\n",
    "\n",
    "#### 6. **FFmpeg Errors**\n",
    "```python\n",
    "# Reinstall FFmpeg:\n",
    "!apt-get install --reinstall -y ffmpeg\n",
    "```\n",
    "\n",
    "#### 7. **Import Errors**\n",
    "```python\n",
    "# Restart runtime and run all cells in order\n",
    "# Runtime ‚Üí Restart runtime\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-test"
   },
   "source": [
    "## üß™ Quick Test (Optional)\n",
    "\n",
    "Test the installation with a simple command-line generation before launching the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-installation"
   },
   "outputs": [],
   "source": [
    "# Quick test to verify everything is working\n",
    "print(\"üß™ Testing installation...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test imports\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    import gradio as gr\n",
    "    from chatterbox.src.chatterbox.tts import ChatterboxTTS\n",
    "    \n",
    "    print(\"‚úÖ Core imports successful\")\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"‚úÖ Gradio: {gr.__version__}\")\n",
    "    \n",
    "    # Test optional imports\n",
    "    try:\n",
    "        import pyrnnoise\n",
    "        print(\"‚úÖ pyrnnoise (RNNoise) available - artifact reduction enabled!\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  pyrnnoise not available - denoising will be skipped\")\n",
    "    \n",
    "    try:\n",
    "        from faster_whisper import WhisperModel\n",
    "        print(\"‚úÖ faster-whisper available\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  faster-whisper not available\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Installation test passed! Ready to use.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Installation test failed: {e}\")\n",
    "    print(\"Please run the installation cells again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-tips"
   },
   "source": [
    "## üí° Usage Tips\n",
    "\n",
    "### Getting the Best Results:\n",
    "\n",
    "1. **Reference Audio**: Upload a clean 3-10 second sample of the target voice\n",
    "2. **Text Preprocessing**: Enable all text cleanup options\n",
    "3. **Quality Settings**: \n",
    "   - Use 3-5 candidates per chunk\n",
    "   - Enable Whisper validation\n",
    "   - Enable RNNoise denoising\n",
    "4. **Export**: Choose FLAC for best quality or MP3 for smaller files\n",
    "\n",
    "### Saving Your Work:\n",
    "\n",
    "Generated audio files are saved in the `output/` directory. Download them before your session ends:\n",
    "\n",
    "```python\n",
    "# List generated files\n",
    "!ls -lh output/\n",
    "\n",
    "# Download all output files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "for file in os.listdir('output'):\n",
    "    if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "        files.download(f'output/{file}')\n",
    "```\n",
    "\n",
    "### Managing Memory:\n",
    "\n",
    "```python\n",
    "# Clear GPU memory if needed\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"GPU memory cleared\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-outputs"
   },
   "source": [
    "## üì• Download Generated Audio Files\n",
    "\n",
    "Use this cell to download all generated audio files to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-files"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üìÅ Available output files:\\n\")\n",
    "\n",
    "if os.path.exists('output'):\n",
    "    output_files = [f for f in os.listdir('output') if f.endswith(('.wav', '.mp3', '.flac'))]\n",
    "    \n",
    "    if output_files:\n",
    "        for file in output_files:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "        print(\"\\nüì• Downloading files...\")\n",
    "        for file in output_files:\n",
    "            try:\n",
    "                files.download(f'output/{file}')\n",
    "                print(f\"‚úÖ Downloaded: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to download {file}: {e}\")\n",
    "    else:\n",
    "        print(\"No audio files found. Generate some audio first!\")\n",
    "else:\n",
    "    print(\"Output directory not found. Generate some audio first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clear-memory"
   },
   "source": [
    "## üßπ Clear GPU Memory\n",
    "\n",
    "Run this cell if you encounter memory issues or want to free up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clear-gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "print(\"üßπ Clearing GPU memory...\\n\")\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Get memory stats\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    \n",
    "    print(f\"GPU Memory Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"GPU Memory Reserved: {reserved:.2f} GB\")\n",
    "\n",
    "# Run garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n‚úÖ Memory cleared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "language-learning"
   },
   "source": [
    "## üåç Language Learning Content Generation (Multilingual)\n",
    "\n",
    "Generate language learning content with **proper multilingual pronunciation**! This example demonstrates using the Chatterbox Multilingual model for authentic language learning materials.\n",
    "\n",
    "This example creates German-English dialogue content with:\n",
    "- **German-only version** (each line repeated twice with authentic German pronunciation)\n",
    "- **German-English paired version** (DE‚ÜíEN‚ÜíDE‚ÜíEN for each line)\n",
    "\n",
    "### ‚ú® What's New?\n",
    "\n",
    "- Uses **real multilingual model** from ResembleAI/chatterbox for proper pronunciation\n",
    "- Supports **23 languages**: ar, da, de, el, en, es, fi, fr, he, hi, it, ja, ko, ms, nl, no, pl, pt, ru, sv, sw, tr, zh\n",
    "- Compatible with all artifact reduction features (RNNoise, Whisper validation, Auto-Editor)\n",
    "- Uses **MTLTokenizer** with language-specific preprocessing\n",
    "\n",
    "### üìù Usage Notes:\n",
    "\n",
    "1. The multilingual model will be downloaded on first use (~2-3GB)\n",
    "2. You can use reference audio files for voice cloning in any supported language\n",
    "3. The same multilingual support is also available in the main UI by enabling \"Multilingual Model\" checkbox\n",
    "\n",
    "**Tip**: Upload your own reference audio files and update the `ref_map` paths for personalized voices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "language-learning-generation"
   },
   "outputs": [],
   "source": [
    "# Language Learning Content Generator with Multilingual Support\n",
    "# This cell demonstrates how to use the multilingual TTS model for language learning\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "from chatterbox.src.chatterbox.tts import ChatterboxTTS\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --- Load MULTILINGUAL model ---\n",
    "print(\"Loading ChatterboxTTS MULTILINGUAL model...\")\n",
    "print(\"‚ö†Ô∏è  Note: The multilingual model may take longer to download on first use.\")\n",
    "print(\"   It will download from ResembleAI/chatterbox (multilingual model files).\")\n",
    "\n",
    "model = ChatterboxTTS.from_pretrained(device=device, use_multilingual=True)\n",
    "sr = model.sr\n",
    "print(\"‚úÖ Multilingual model loaded! Sample rate:\", sr)\n",
    "print(f\"   Supports 23 languages: de, fr, es, it, pt, ru, nl, pl, tr, ar, zh, ja, ko, hi, and more!\")\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def make_silence(duration_sec, sr):\n",
    "    return np.zeros(int(duration_sec * sr), dtype=np.float32)\n",
    "\n",
    "def trim_clip(wav, top_db=35):\n",
    "    \"\"\"Remove trailing/leading noise\"\"\"\n",
    "    trimmed, _ = librosa.effects.trim(wav, top_db=top_db)\n",
    "    return trimmed.astype(np.float32)\n",
    "\n",
    "def normalize(wav):\n",
    "    \"\"\"Normalize loudness\"\"\"\n",
    "    if np.max(np.abs(wav)) > 0:\n",
    "        wav = wav / np.max(np.abs(wav)) * 0.97\n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "def safe_generate(model, text, language_id=\"en\", audio_prompt_path=None,\n",
    "                  cfg_weight=0.5, exaggeration=0.5):\n",
    "    \"\"\"\n",
    "    Generate speech with language support.\n",
    "    \n",
    "    Args:\n",
    "        model: ChatterboxTTS model instance\n",
    "        text: Text to synthesize\n",
    "        language_id: Language code (en, de, fr, es, it, pt, etc.)\n",
    "        audio_prompt_path: Optional reference audio for voice cloning\n",
    "        cfg_weight: CFG weight (0.0-1.0)\n",
    "        exaggeration: Emotion exaggeration (0.0-2.0)\n",
    "    \"\"\"\n",
    "    wav = model.generate(\n",
    "        text,\n",
    "        audio_prompt_path=audio_prompt_path,\n",
    "        language_id=language_id,\n",
    "        cfg_weight=cfg_weight,\n",
    "        exaggeration=exaggeration\n",
    "    )\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav = wav.detach().cpu().numpy()\n",
    "    wav = np.asarray(wav).reshape(-1).astype(np.float32)\n",
    "    return normalize(trim_clip(wav))\n",
    "\n",
    "# -------------------- Dialogue --------------------\n",
    "\n",
    "turns = [\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Hallo Markus, sch√∂n dich zu sehen! Wie geht's dir?\",\n",
    "     \"english\":\"Hello Markus, nice to see you! How are you?\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Mir geht's gut, danke! Und dir?\",\n",
    "     \"english\":\"I'm doing well, thanks! And you?\"},\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Auch gut! Hast du Lust, einen Kaffee zu trinken?\",\n",
    "     \"english\":\"I'm good too! Do you feel like having a coffee?\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Sehr gerne. Ich nehme einen Cappuccino.\",\n",
    "     \"english\":\"Gladly. I'll have a cappuccino.\"},\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Perfekt, ich nehme einen Latte Macchiato. Und danach k√∂nnen wir einen Spaziergang machen.\",\n",
    "     \"english\":\"Perfect, I'll take a latte macchiato. And after that we can go for a walk.\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Das klingt wunderbar. Ich freue mich schon!\",\n",
    "     \"english\":\"That sounds wonderful. I'm looking forward to it!\"},\n",
    "]\n",
    "\n",
    "# Optional: reference voices (upload your own clean reference files)\n",
    "# If you have reference files, upload them to Colab and update these paths:\n",
    "ref_map = {\n",
    "    \"Anna\": None,    # e.g., \"/content/anna_ref.wav\" if you upload one\n",
    "    \"Markus\": None   # e.g., \"/content/markus_ref.wav\" if you upload one\n",
    "}\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# -------------------- 1) German-only --------------------\n",
    "\n",
    "german_clips = []\n",
    "print(\"\\nüéôÔ∏è  Generating: German-only (each turn x2)\")\n",
    "for t in turns:\n",
    "    speaker, text_de = t[\"speaker\"], t[\"german\"]\n",
    "    ref = ref_map.get(speaker)\n",
    "    for _ in range(2):\n",
    "        print(f\"{speaker} (DE): {text_de}\")\n",
    "        german_clips.append(safe_generate(model, text_de, language_id=\"de\", audio_prompt_path=ref))\n",
    "        german_clips.append(make_silence(0.4, sr))  # short pause between repeats\n",
    "    german_clips.append(make_silence(0.8, sr))      # pause between speakers\n",
    "\n",
    "german_full = np.concatenate(german_clips)\n",
    "sf.write(\"output/german_only_full.wav\", german_full, sr)\n",
    "print(\"üéß Saved: output/german_only_full.wav\")\n",
    "\n",
    "# -------------------- 2) German+English pairs --------------------\n",
    "\n",
    "pair_clips = []\n",
    "print(\"\\nüéôÔ∏è  Generating: German+English (each turn repeated DE‚ÜíEN‚ÜíDE‚ÜíEN)\")\n",
    "for t in turns:\n",
    "    speaker = t[\"speaker\"]\n",
    "    ref = ref_map.get(speaker)\n",
    "    seq = [(t[\"german\"], \"de\"), (t[\"english\"], \"en\")] * 2\n",
    "    for s_text, s_lang in seq:\n",
    "        lang_name = \"German\" if s_lang == \"de\" else \"English\"\n",
    "        print(f\"{speaker} ({lang_name}): {s_text}\")\n",
    "        pair_clips.append(safe_generate(model, s_text, language_id=s_lang, audio_prompt_path=ref))\n",
    "        pair_clips.append(make_silence(0.35, sr))  # pause inside pair\n",
    "    pair_clips.append(make_silence(0.9, sr))      # pause between speakers\n",
    "\n",
    "pair_full = np.concatenate(pair_clips)\n",
    "sf.write(\"output/german_with_translation.wav\", pair_full, sr)\n",
    "print(\"üéß Saved: output/german_with_translation.wav\")\n",
    "\n",
    "print(\"\\n‚úÖ Done! Files saved to output/ directory\")\n",
    "print(\"üì• Download them using the file browser or the download cell above.\")\n",
    "\n",
    "print(\"\\nüí° Tips:\")\n",
    "print(\"   ‚Ä¢ The multilingual model uses authentic language-specific pronunciation\")\n",
    "print(\"   ‚Ä¢ Supported languages: ar, da, de, el, en, es, fi, fr, he, hi, it, ja, ko, ms, nl, no, pl, pt, ru, sv, sw, tr, zh\")\n",
    "print(\"   ‚Ä¢ Upload reference audio files for better voice consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **GitHub Repository**: [Chatterbox-TTS-Extended](https://github.com/m-marie1/Chatterbox-TTS-Extended)\n",
    "- **Original Chatterbox**: [Resemble AI Chatterbox](https://github.com/resemble-ai/chatterbox)\n",
    "- **Report Issues**: [GitHub Issues](https://github.com/m-marie1/Chatterbox-TTS-Extended/issues)\n",
    "\n",
    "## ü§ù Credits\n",
    "\n",
    "- **Chatterbox-TTS-Extended**: Extended version with artifact reduction\n",
    "- **Original Chatterbox**: Resemble AI\n",
    "- **RNNoise**: Xiph.Org Foundation\n",
    "- **Whisper**: OpenAI\n",
    "\n",
    "---\n",
    "\n",
    "**Enjoy high-quality, artifact-free speech synthesis! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}