{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# \ud83c\udfa7 Chatterbox-TTS-Extended on Google Colab\n",
    "\n",
    "## Advanced Text-to-Speech with Artifact Reduction\n",
    "\n",
    "This notebook allows you to run Chatterbox-TTS-Extended on Google Colab, leveraging free GPU resources for high-quality speech synthesis with built-in artifact reduction.\n",
    "\n",
    "### Features:\n",
    "- \ud83c\udfa4 High-quality voice cloning and TTS\n",
    "- \ud83d\udd27 Advanced artifact reduction with RNNoise\n",
    "- \ud83c\udfaf Whisper-based quality validation\n",
    "- \ud83c\udfa8 Voice conversion capabilities\n",
    "- \ud83d\udce6 Multiple export formats (WAV, MP3, FLAC)\n",
    "\n",
    "### Requirements:\n",
    "- Google Colab account (free tier works!)\n",
    "- GPU runtime (recommended: T4 or better)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-links"
   },
   "source": [
    "## \ud83d\udcda Quick Links & Resources\n",
    "\n",
    "**Documentation:**\n",
    "- \ud83d\udcd6 [Full Colab Guide](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/COLAB_GUIDE.md) - Comprehensive guide\n",
    "- \u26a1 [Quick Reference](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/COLAB_QUICKREF.md) - Cheat sheet\n",
    "- \ud83d\udccb [README](https://github.com/m-marie1/Chatterbox-TTS-Extended/blob/main/README.md) - Feature documentation\n",
    "\n",
    "**Support:**\n",
    "- \ud83d\udc1b [Report Issues](https://github.com/m-marie1/Chatterbox-TTS-Extended/issues)\n",
    "- \ud83d\udcac [Discussions](https://github.com/m-marie1/Chatterbox-TTS-Extended/discussions)\n",
    "\n",
    "**Tips:**\n",
    "- \u26a1 For fastest start: Run all cells and accept default settings\n",
    "- \ud83c\udfaf For best quality: Enable RNNoise + use 3 candidates + Whisper validation\n",
    "- \ud83d\udcbe Remember to download files before session ends!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## \ud83d\udccb Step 1: Environment Setup\n",
    "\n",
    "**IMPORTANT**: Make sure you have enabled GPU runtime:\n",
    "1. Go to `Runtime` \u2192 `Change runtime type`\n",
    "2. Select `GPU` as Hardware accelerator\n",
    "3. Choose `T4` GPU (or better if available)\n",
    "4. Click `Save`\n",
    "\n",
    "This cell will:\n",
    "- Check GPU availability\n",
    "- Verify Python version\n",
    "- Display system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-environment"
   },
   "outputs": [],
   "source": [
    "# Check GPU and environment\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"\ud83d\udd0d Checking environment...\\n\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi'], encoding='utf-8')\n",
    "    print(\"\\n\u2705 GPU detected:\")\n",
    "    print(gpu_info)\n",
    "except:\n",
    "    print(\"\\n\u26a0\ufe0f  WARNING: No GPU detected. This will be VERY slow!\")\n",
    "    print(\"Please enable GPU: Runtime \u2192 Change runtime type \u2192 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-system-deps"
   },
   "source": [
    "## \ud83d\udce6 Step 2: Install System Dependencies\n",
    "\n",
    "Installing FFmpeg and other system-level tools required for audio processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-ffmpeg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install FFmpeg (required for audio processing)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg\n",
    "\n",
    "# Verify FFmpeg installation\n",
    "!ffmpeg -version | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## \ud83d\udce5 Step 3: Clone Repository\n",
    "\n",
    "Cloning the Chatterbox-TTS-Extended repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "git-clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists('Chatterbox-TTS-Extended'):\n",
    "    print(\"\ud83d\udcc1 Removing existing directory...\")\n",
    "    !rm -rf Chatterbox-TTS-Extended\n",
    "\n",
    "# Clone the repository\n",
    "print(\"\ud83d\udce5 Cloning Chatterbox-TTS-Extended repository...\")\n",
    "!git clone https://github.com/m-marie1/Chatterbox-TTS-Extended.git\n",
    "\n",
    "# Change to repository directory\n",
    "%cd Chatterbox-TTS-Extended\n",
    "\n",
    "print(\"\\n\u2705 Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-python-deps"
   },
   "source": [
    "## \ud83d\udc0d Step 4: Install Python Dependencies\n",
    "\n",
    "Installing all required Python packages. This may take 3-5 minutes.\n",
    "\n",
    "**Note**: We're using Colab-optimized versions to avoid conflicts with pre-installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA support (Colab uses CUDA 12.x)\n",
    "print(\"\ud83d\udd27 Installing PyTorch with CUDA support...\")\n",
    "!pip install -q torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install core dependencies\n",
    "print(\"\\n\ud83d\udce6 Installing core dependencies...\")\n",
    "!pip install -q gradio numpy faster-whisper openai-whisper ffmpeg-python\n",
    "!pip install -q resampy==0.4.3 librosa==0.10.0 soundfile nltk\n",
    "\n",
    "# Install auto-editor for audio cleanup\n",
    "print(\"\\n\ud83c\udfac Installing auto-editor...\")\n",
    "!pip install -q auto-editor==27.1.1\n",
    "\n",
    "# Install Hugging Face and model dependencies\n",
    "print(\"\\n\ud83e\udd17 Installing Hugging Face dependencies...\")\n",
    "!pip install -q transformers==4.46.3 diffusers==0.29.0 omegaconf==2.3.0\n",
    "\n",
    "# Install specific model dependencies\n",
    "print(\"\\n\ud83c\udfaf Installing model-specific dependencies...\")\n",
    "!pip install -q resemble-perth==1.0.1 silero-vad==5.1.2 conformer==0.3.2\n",
    "\n",
    "# Install pyrnnoise for artifact reduction\n",
    "print(\"\\n\ud83d\udd07 Installing pyrnnoise for noise reduction...\")\n",
    "!pip install -q pyrnnoise==0.3.8\n",
    "\n",
    "# Install s3tokenizer\n",
    "print(\"\\n\ud83d\udd24 Installing s3tokenizer...\")\n",
    "!pip install -q s3tokenizer\n",
    "\n",
    "# Install spaces (for Gradio compatibility)\n",
    "print(\"\\n\ud83d\ude80 Installing spaces...\")\n",
    "!pip install -q spaces\n",
    "\n",
    "print(\"\\n\u2705 All dependencies installed successfully!\")\n",
    "\n",
    "# Verify key installations\n",
    "print(\"\\n\ud83d\udcca Verifying installations...\")\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-nltk"
   },
   "source": [
    "## \ud83d\udcda Step 5: Download NLTK Data\n",
    "\n",
    "Downloading required NLTK tokenizer data for text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nltk-download"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "print(\"\ud83d\udcda Downloading NLTK data...\")\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "print(\"\u2705 NLTK data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "launch-ui"
   },
   "source": [
    "## \ud83d\ude80 Step 6: Launch Chatterbox-TTS-Extended\n",
    "\n",
    "This will start the Gradio interface. The model will be loaded on first use.\n",
    "\n",
    "**Features available:**\n",
    "- **TTS Tab**: Text-to-Speech with advanced options\n",
    "  - Multiple candidate generation for best quality\n",
    "  - Whisper validation to reduce artifacts\n",
    "  - RNNoise denoising for clean audio\n",
    "  - Auto-editor for silence removal\n",
    "  - Batch processing support\n",
    "- **Voice Conversion Tab**: Convert voice to match a reference\n",
    "\n",
    "**Tips for Colab:**\n",
    "- First generation will take longer as models load\n",
    "- Use smaller Whisper models (tiny/base) to save VRAM\n",
    "- Enable \"Use faster-whisper\" for better performance\n",
    "- Start with 1-2 candidates per chunk to avoid OOM errors\n",
    "- If you get CUDA out of memory, restart runtime and reduce settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch-app",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Launch the Gradio interface\n",
    "print(\"\ud83d\ude80 Launching Chatterbox-TTS-Extended...\\n\")\n",
    "print(\"\u23f3 First generation will take longer as models download and load.\")\n",
    "print(\"\ud83d\udcca Monitor the output below for progress updates.\\n\")\n",
    "\n",
    "# Run with public sharing enabled for Colab\n",
    "!python Chatter.py --share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "recommended-settings"
   },
   "source": [
    "## \u2699\ufe0f Recommended Settings for Colab\n",
    "\n",
    "### For Free Tier (T4 GPU, ~15GB VRAM):\n",
    "```\n",
    "Whisper Model: tiny or base\n",
    "Use faster-whisper: \u2705 Enabled\n",
    "Candidates per chunk: 2-3\n",
    "Parallel workers: 2-3\n",
    "Enable RNNoise: \u2705 Enabled (removes artifacts!)\n",
    "```\n",
    "\n",
    "### For Pro/Pro+ (A100/V100, more VRAM):\n",
    "```\n",
    "Whisper Model: small or medium\n",
    "Use faster-whisper: \u2705 Enabled\n",
    "Candidates per chunk: 3-5\n",
    "Parallel workers: 4-6\n",
    "Enable RNNoise: \u2705 Enabled\n",
    "```\n",
    "\n",
    "### To Reduce Artifacts (Main Goal!):\n",
    "1. **Enable RNNoise denoising** - This is the key feature!\n",
    "2. Use **3+ candidates per chunk** with Whisper validation\n",
    "3. Enable **Auto-Editor** for cleanup\n",
    "4. Use **faster-whisper** for efficient validation\n",
    "5. Set **Max Attempts to 3** to retry failed chunks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## \ud83d\udd27 Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "#### 1. **CUDA Out of Memory Error**\n",
    "```python\n",
    "# Solution: Restart runtime and reduce settings\n",
    "# Runtime \u2192 Restart runtime\n",
    "# Then use these settings:\n",
    "# - Whisper model: tiny\n",
    "# - Candidates: 1-2\n",
    "# - Parallel workers: 1\n",
    "```\n",
    "\n",
    "#### 2. **Slow Performance**\n",
    "```python\n",
    "# Make sure GPU is enabled:\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "# If False, go to Runtime \u2192 Change runtime type \u2192 GPU\n",
    "```\n",
    "\n",
    "#### 3. **Model Download Failures**\n",
    "```python\n",
    "# Retry the cell or check your internet connection\n",
    "# Models are downloaded from Hugging Face on first use\n",
    "```\n",
    "\n",
    "#### 4. **Audio Has Noise/Artifacts**\n",
    "```python\n",
    "# Enable these features in the UI:\n",
    "# \u2705 Denoise with RNNoise (pyrnnoise)\n",
    "# \u2705 Post-process with Auto-Editor\n",
    "# \u2705 Use faster-whisper validation\n",
    "# Increase candidates per chunk to 3-5\n",
    "```\n",
    "\n",
    "#### 5. **Session Timeout**\n",
    "```python\n",
    "# Colab free tier has time limits\n",
    "# Save your audio files regularly\n",
    "# Consider upgrading to Colab Pro for longer sessions\n",
    "```\n",
    "\n",
    "#### 6. **FFmpeg Errors**\n",
    "```python\n",
    "# Reinstall FFmpeg:\n",
    "!apt-get install --reinstall -y ffmpeg\n",
    "```\n",
    "\n",
    "#### 7. **Import Errors**\n",
    "```python\n",
    "# Restart runtime and run all cells in order\n",
    "# Runtime \u2192 Restart runtime\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick-test"
   },
   "source": [
    "## \ud83e\uddea Quick Test (Optional)\n",
    "\n",
    "Test the installation with a simple command-line generation before launching the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-installation"
   },
   "outputs": [],
   "source": [
    "# Quick test to verify everything is working\n",
    "print(\"\ud83e\uddea Testing installation...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test imports\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    import gradio as gr\n",
    "    from chatterbox.src.chatterbox.tts import ChatterboxTTS\n",
    "    \n",
    "    print(\"\u2705 Core imports successful\")\n",
    "    print(f\"\u2705 PyTorch: {torch.__version__}\")\n",
    "    print(f\"\u2705 CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"\u2705 Gradio: {gr.__version__}\")\n",
    "    \n",
    "    # Test optional imports\n",
    "    try:\n",
    "        import pyrnnoise\n",
    "        print(\"\u2705 pyrnnoise (RNNoise) available - artifact reduction enabled!\")\n",
    "    except:\n",
    "        print(\"\u26a0\ufe0f  pyrnnoise not available - denoising will be skipped\")\n",
    "    \n",
    "    try:\n",
    "        from faster_whisper import WhisperModel\n",
    "        print(\"\u2705 faster-whisper available\")\n",
    "    except:\n",
    "        print(\"\u26a0\ufe0f  faster-whisper not available\")\n",
    "    \n",
    "    print(\"\\n\u2705 Installation test passed! Ready to use.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n\u274c Installation test failed: {e}\")\n",
    "    print(\"Please run the installation cells again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-tips"
   },
   "source": [
    "## \ud83d\udca1 Usage Tips\n",
    "\n",
    "### Getting the Best Results:\n",
    "\n",
    "1. **Reference Audio**: Upload a clean 3-10 second sample of the target voice\n",
    "2. **Text Preprocessing**: Enable all text cleanup options\n",
    "3. **Quality Settings**: \n",
    "   - Use 3-5 candidates per chunk\n",
    "   - Enable Whisper validation\n",
    "   - Enable RNNoise denoising\n",
    "4. **Export**: Choose FLAC for best quality or MP3 for smaller files\n",
    "\n",
    "### Saving Your Work:\n",
    "\n",
    "Generated audio files are saved in the `output/` directory. Download them before your session ends:\n",
    "\n",
    "```python\n",
    "# List generated files\n",
    "!ls -lh output/\n",
    "\n",
    "# Download all output files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "for file in os.listdir('output'):\n",
    "    if file.endswith(('.wav', '.mp3', '.flac')):\n",
    "        files.download(f'output/{file}')\n",
    "```\n",
    "\n",
    "### Managing Memory:\n",
    "\n",
    "```python\n",
    "# Clear GPU memory if needed\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"GPU memory cleared\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-outputs"
   },
   "source": [
    "## \ud83d\udce5 Download Generated Audio Files\n",
    "\n",
    "Use this cell to download all generated audio files to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-files"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"\ud83d\udcc1 Available output files:\\n\")\n",
    "\n",
    "if os.path.exists('output'):\n",
    "    output_files = [f for f in os.listdir('output') if f.endswith(('.wav', '.mp3', '.flac'))]\n",
    "    \n",
    "    if output_files:\n",
    "        for file in output_files:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "        print(\"\\n\ud83d\udce5 Downloading files...\")\n",
    "        for file in output_files:\n",
    "            try:\n",
    "                files.download(f'output/{file}')\n",
    "                print(f\"\u2705 Downloaded: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u274c Failed to download {file}: {e}\")\n",
    "    else:\n",
    "        print(\"No audio files found. Generate some audio first!\")\n",
    "else:\n",
    "    print(\"Output directory not found. Generate some audio first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clear-memory"
   },
   "source": [
    "## \ud83e\uddf9 Clear GPU Memory\n",
    "\n",
    "Run this cell if you encounter memory issues or want to free up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clear-gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "print(\"\ud83e\uddf9 Clearing GPU memory...\\n\")\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Get memory stats\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1024**3\n",
    "    \n",
    "    print(f\"GPU Memory Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"GPU Memory Reserved: {reserved:.2f} GB\")\n",
    "\n",
    "# Run garbage collection\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\u2705 Memory cleared!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "language-learning"
   },
   "source": [
    "## \ud83c\udf0d Language Learning Content Generation\n",
    "\n",
    "Generate language learning content with translations. Perfect for creating dialogue practice materials.\n",
    "\n",
    "This example creates German-English dialogue content with:\n",
    "- German-only version (each line repeated twice)\n",
    "- German-English paired version (DE\u2192EN\u2192DE\u2192EN for each line)\n",
    "\n",
    "**Note**: This uses the Chatterbox model's built-in multilingual capabilities. If you want specific voices, upload reference audio files and update the `ref_map` paths accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "language-learning-generation"
   },
   "outputs": [],
   "source": [
    "# Language Learning Content Generator\n",
    "# Paste this into a cell after the main UI has been launched\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "from chatterbox.src.chatterbox.tts import ChatterboxTTS\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --- Load model ---\n",
    "print(\"Loading ChatterboxTTS (this may take a few minutes if not already loaded)...\")\n",
    "model = ChatterboxTTS.from_pretrained(device=device)\n",
    "sr = model.sr\n",
    "print(\"\u2705 Loaded. Sample rate:\", sr)\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "\n",
    "def make_silence(duration_sec, sr):\n",
    "    return np.zeros(int(duration_sec * sr), dtype=np.float32)\n",
    "\n",
    "def trim_clip(wav, top_db=35):\n",
    "    \"\"\"Remove trailing/leading noise\"\"\"\n",
    "    trimmed, _ = librosa.effects.trim(wav, top_db=top_db)\n",
    "    return trimmed.astype(np.float32)\n",
    "\n",
    "def normalize(wav):\n",
    "    \"\"\"Normalize loudness\"\"\"\n",
    "    if np.max(np.abs(wav)) > 0:\n",
    "        wav = wav / np.max(np.abs(wav)) * 0.97\n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "def safe_generate(model, text, language_id=None, audio_prompt_path=None,\n",
    "                  cfg_weight=0.5, exaggeration=0.5):\n",
    "    \"\"\"Robust generate wrapper\"\"\"\n",
    "    kwargs = {}\n",
    "    if language_id is not None:\n",
    "        kwargs[\"language_id\"] = language_id\n",
    "    if audio_prompt_path is not None:\n",
    "        kwargs[\"audio_prompt_path\"] = audio_prompt_path\n",
    "\n",
    "    try:\n",
    "        wav = model.generate(text, cfg_weight=cfg_weight,\n",
    "                             exaggeration=exaggeration, **kwargs)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            wav = model.generate(text, **kwargs)\n",
    "        except TypeError:\n",
    "            wav = model.generate(text)\n",
    "\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav = wav.detach().cpu().numpy()\n",
    "    wav = np.asarray(wav).reshape(-1).astype(np.float32)\n",
    "\n",
    "    return normalize(trim_clip(wav))\n",
    "\n",
    "# -------------------- Dialogue --------------------\n",
    "\n",
    "turns = [\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Hallo Markus, sch\u00f6n dich zu sehen! Wie geht's dir?\",\n",
    "     \"english\":\"Hello Markus, nice to see you! How are you?\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Mir geht's gut, danke! Und dir?\",\n",
    "     \"english\":\"I'm doing well, thanks! And you?\"},\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Auch gut! Hast du Lust, einen Kaffee zu trinken?\",\n",
    "     \"english\":\"I'm good too! Do you feel like having a coffee?\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Sehr gerne. Ich nehme einen Cappuccino.\",\n",
    "     \"english\":\"Gladly. I'll have a cappuccino.\"},\n",
    "    {\"speaker\":\"Anna\",\n",
    "     \"german\":\"Perfekt, ich nehme einen Latte Macchiato. Und danach k\u00f6nnen wir einen Spaziergang machen.\",\n",
    "     \"english\":\"Perfect, I'll take a latte macchiato. And after that we can go for a walk.\"},\n",
    "    {\"speaker\":\"Markus\",\n",
    "     \"german\":\"Das klingt wunderbar. Ich freue mich schon!\",\n",
    "     \"english\":\"That sounds wonderful. I'm looking forward to it!\"},\n",
    "]\n",
    "\n",
    "# Optional: reference voices (upload your own clean reference files)\n",
    "# If you have reference files, upload them to Colab and update these paths:\n",
    "ref_map = {\n",
    "    \"Anna\": None,    # e.g., \"/content/anna_ref.wav\" if you upload one\n",
    "    \"Markus\": None   # e.g., \"/content/markus_ref.wav\" if you upload one\n",
    "}\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# -------------------- 1) German-only --------------------\n",
    "\n",
    "german_clips = []\n",
    "print(\"\\n\ud83c\udf99\ufe0f Generating: German-only (each turn x2)\")\n",
    "for t in turns:\n",
    "    speaker, text_de = t[\"speaker\"], t[\"german\"]\n",
    "    ref = ref_map.get(speaker)\n",
    "    for _ in range(2):\n",
    "        print(f\"{speaker} (DE): {text_de}\")\n",
    "        german_clips.append(safe_generate(model, text_de, language_id=\"de\", audio_prompt_path=ref))\n",
    "        german_clips.append(make_silence(0.4, sr))  # short pause between repeats\n",
    "    german_clips.append(make_silence(0.8, sr))      # pause between speakers\n",
    "\n",
    "german_full = np.concatenate(german_clips)\n",
    "sf.write(\"output/german_only_full.wav\", german_full, sr)\n",
    "print(\"\ud83c\udfa7 Saved: output/german_only_full.wav\")\n",
    "\n",
    "# -------------------- 2) German+English pairs --------------------\n",
    "\n",
    "pair_clips = []\n",
    "print(\"\\n\ud83c\udf99\ufe0f Generating: German+English (each turn repeated DE\u2192EN\u2192DE\u2192EN)\")\n",
    "for t in turns:\n",
    "    speaker = t[\"speaker\"]\n",
    "    ref = ref_map.get(speaker)\n",
    "    seq = [(t[\"german\"], \"de\"), (t[\"english\"], \"en\")] * 2\n",
    "    for s_text, s_lang in seq:\n",
    "        print(f\"{speaker} ({s_lang}): {s_text}\")\n",
    "        pair_clips.append(safe_generate(model, s_text, language_id=s_lang, audio_prompt_path=ref))\n",
    "        pair_clips.append(make_silence(0.35, sr))  # pause inside pair\n",
    "    pair_clips.append(make_silence(0.9, sr))      # pause between speakers\n",
    "\n",
    "pair_full = np.concatenate(pair_clips)\n",
    "sf.write(\"output/german_with_translation.wav\", pair_full, sr)\n",
    "print(\"\ud83c\udfa7 Saved: output/german_with_translation.wav\")\n",
    "\n",
    "print(\"\\n\u2705 Done! Files saved to output/ directory\")\n",
    "print(\"\ud83d\udce5 Use the 'Download Generated Audio Files' cell above to download them.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcda Additional Resources\n",
    "\n",
    "- **GitHub Repository**: [Chatterbox-TTS-Extended](https://github.com/m-marie1/Chatterbox-TTS-Extended)\n",
    "- **Original Chatterbox**: [Resemble AI Chatterbox](https://github.com/resemble-ai/chatterbox)\n",
    "- **Report Issues**: [GitHub Issues](https://github.com/m-marie1/Chatterbox-TTS-Extended/issues)\n",
    "\n",
    "## \ud83e\udd1d Credits\n",
    "\n",
    "- **Chatterbox-TTS-Extended**: Extended version with artifact reduction\n",
    "- **Original Chatterbox**: Resemble AI\n",
    "- **RNNoise**: Xiph.Org Foundation\n",
    "- **Whisper**: OpenAI\n",
    "\n",
    "---\n",
    "\n",
    "**Enjoy high-quality, artifact-free speech synthesis! \ud83c\udf89**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}